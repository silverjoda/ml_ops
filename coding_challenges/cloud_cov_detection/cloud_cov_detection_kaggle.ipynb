{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543898e-2b27-4c49-ba11-b636333c452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from PIL import Image\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee41231-8a96-4eba-9eb7-96f508590856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
    "\n",
    "print(\"device name\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe923b12-130f-4eb7-8987-3a70a1a825c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Loop through the files in red folder and combine, into a dictionary, the other bands\n",
    "        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n",
    "        self.pytorch = pytorch\n",
    "        \n",
    "    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):    \n",
    "        files = {'red': r_file, \n",
    "                 'green':g_dir/r_file.name.replace('red', 'green'),\n",
    "                 'blue': b_dir/r_file.name.replace('red', 'blue'), \n",
    "                 'nir': nir_dir/r_file.name.replace('red', 'nir'),\n",
    "                 'gt': gt_dir/r_file.name.replace('red', 'gt')}\n",
    "\n",
    "        return files\n",
    "                                       \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.files)\n",
    "     \n",
    "    def open_as_array(self, idx, invert=False, include_nir=False):\n",
    "\n",
    "        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n",
    "                            np.array(Image.open(self.files[idx]['green'])),\n",
    "                            np.array(Image.open(self.files[idx]['blue'])),\n",
    "                           ], axis=2)\n",
    "    \n",
    "        if include_nir:\n",
    "            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n",
    "            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n",
    "    \n",
    "        if invert:\n",
    "            raw_rgb = raw_rgb.transpose((2,0,1))\n",
    "    \n",
    "        # normalize\n",
    "        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n",
    "    \n",
    "\n",
    "    def open_mask(self, idx, add_dims=False):\n",
    "        \n",
    "        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n",
    "        raw_mask = np.where(raw_mask==255, 1, 0)\n",
    "        \n",
    "        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n",
    "        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144dcd40-d143-4841-b61e-7818d7764252",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('data/38-Cloud_training')\n",
    "data = CloudDataset(base_path/'train_red', \n",
    "                    base_path/'train_green', \n",
    "                    base_path/'train_blue', \n",
    "                    base_path/'train_nir',\n",
    "                    base_path/'train_gt')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ebc9c-fa8e-4ba4-b8aa-a591e3715c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns features x and target feature y\n",
    "x, y = data[1000]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc970d-4f26-47ab-8aa6-3165109081f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize raw image and ground truth\n",
    "image_index = 1000\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,9))\n",
    "ax[0].imshow(data.open_as_array(image_index))\n",
    "ax[1].imshow(data.open_mask(image_index))\n",
    "\n",
    "# left -> raw image\n",
    "# right Ground-Truth Mask (as binary image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17193aa-c168-422a-a225-1514280bd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = torch.utils.data.random_split(data, (6000, 2400))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95beeb-3bf1-468a-941b-47c3cbd5e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloads sample from dataset\n",
    "\n",
    "train_dataload = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataload = DataLoader(valid_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830c982-bafe-4803-82c9-924c477a6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataload\n",
    "xb, yb = next(iter(train_dataload))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35b3dc-1a85-47b9-823f-0111cc5efa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n",
    "        self.conv2 = self.contract_block(32, 64, 3, 1)\n",
    "        self.conv3 = self.contract_block(64, 128, 3, 1)\n",
    "\n",
    "        self.upconv3 = self.expand_block(128, 64, 3, 1)\n",
    "        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n",
    "        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        # downsampling part\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "\n",
    "        upconv3 = self.upconv3(conv3)\n",
    "\n",
    "        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n",
    "        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n",
    "\n",
    "        return upconv1\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        contract = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "                                 )\n",
    "\n",
    "        return contract\n",
    "\n",
    "    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                            torch.nn.BatchNorm2d(out_channels),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                            torch.nn.BatchNorm2d(out_channels),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "                            )\n",
    "        return expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ebc2da-39a2-4d15-9a00-8e93ec8e9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNET(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5924f3b-8fc2-449a-8f2a-aaf466daf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hiddenlayer as hl\n",
    "\n",
    "# transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n",
    "\n",
    "# graph = hl.build_graph(unet, torch.zeros([12, 4, 384, 384]), transforms=transforms)\n",
    "# graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "# graph.save('rnn_hiddenlayer', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec7a33-8362-4c32-8adb-e234c647d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d04e9c-5e6e-4c21-97bd-9397081af885",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataload = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "valid_dataload = DataLoader(valid_dataset, batch_size=6, shuffle=True)\n",
    "\n",
    "# testing one pass\n",
    "xb, yb = next(iter(train_dataload))\n",
    "xb.shape, yb.shape\n",
    "\n",
    "pred = unet(xb)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86916be-ffb0-4b76-be0b-1db88ec5c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):\n",
    "    start = time.time()\n",
    "    model.cuda()\n",
    "\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set trainind mode = true\n",
    "                dataloader = train_dataload\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                dataloader = valid_dataload\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "            step = 0\n",
    "\n",
    "            # iterate over data\n",
    "            for x, y in dataloader:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "                step += 1\n",
    "\n",
    "                # forward pass\n",
    "                if phase == 'train':\n",
    "                    # zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(x)\n",
    "                    loss = loss_fn(outputs, y)\n",
    "\n",
    "                    # the backward pass frees the graph memory, so there is no \n",
    "                    # need for torch.no_grad in this training pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    # scheduler.step()\n",
    "\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(x)\n",
    "                        loss = loss_fn(outputs, y.long())\n",
    "\n",
    "                # stats - whatever is the phase\n",
    "                acc = acc_fn(outputs, y)\n",
    "\n",
    "                running_acc  += acc*dataloader.batch_size\n",
    "                running_loss += loss*dataloader.batch_size \n",
    "\n",
    "                if step % 100 == 0:\n",
    "                    # clear_output(wait=True)\n",
    "                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n",
    "                    # print(torch.cuda.memory_summary())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_acc / len(dataloader.dataset)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "            print('-' * 10)\n",
    "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print('-' * 10)\n",
    "\n",
    "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "    \n",
    "    return train_loss, valid_loss    \n",
    "\n",
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a54bf-ca90-4fe3-ae19-6c796f2d7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() # choose loss function\n",
    "opt = torch.optim.Adam(unet.parameters(), lr=0.01) # choose gradient function\n",
    "\n",
    "# start training\n",
    "train_loss, valid_loss = train(unet, train_dataload, valid_dataload, loss_fn, opt, acc_metric, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456013ed-589f-444b-9833-782304a5c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583ed58-1d87-417f-b06e-ec448ef60e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520d9e6-8a48-4f07-acab-3afc1f5d5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gc\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d17b0a-c8b6-4cff-9141-34981d082213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize Result\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot([tl.detach().cpu() for tl in train_loss], label='Train loss')\n",
    "plt.plot([vl.detach().cpu() for vl in valid_loss], label='Valid loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d889cf-74a3-4050-9cac-1791d86ea59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_img(xb, idx):\n",
    "    img = np.array(xb[idx,0:3])\n",
    "    return img.transpose((1,2,0))\n",
    "\n",
    "def predb_to_mask(predb, idx):\n",
    "    p = torch.functional.F.softmax(predb[idx], 0)\n",
    "    return p.argmax(0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a832b-c555-4e08-95e2-d919fc36fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dataload))\n",
    "\n",
    "with torch.no_grad():\n",
    "    predb = unet(xb.cuda())\n",
    "\n",
    "predb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c462804-0051-4e0e-8c1b-10c8bc3ad433",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 12\n",
    "fig, ax = plt.subplots(bs,3, figsize=(15,bs*5))\n",
    "for i in range(bs):\n",
    "    ax[i,0].imshow(batch_to_img(xb,i))\n",
    "    ax[i,1].imshow(yb[i])\n",
    "    ax[i,2].imshow(predb_to_mask(predb, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501bf9f9-3667-41cf-b315-5b62f260a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# Make a model speed benchmark for cpu and GPU \n",
    "def time_cuda_model(model, x, use_cuda=False):\n",
    "    if use_cuda:\n",
    "        x = x.cuda()\n",
    "        model = model.cuda()\n",
    "        \n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        start.record()\n",
    "        with torch.no_grad():\n",
    "            y_ = model(x)\n",
    "        end.record()\n",
    "\n",
    "        # Waits for everything to finish running\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        elapsed_time = start.elapsed_time(end)\n",
    "    else:\n",
    "        if x.is_cuda:\n",
    "            x = x.cpu()\n",
    "        model = model.cpu()\n",
    "        \n",
    "        time_sum = 0\n",
    "        n_trials = 5 \n",
    "        with torch.no_grad():\n",
    "            for i in range(n_trials):    \n",
    "                start = timer()\n",
    "                y_ = model(x)\n",
    "                end = timer()\n",
    "                time_sum += (end-start)\n",
    "        elapsed_time = (time_sum / n_trials) * 1000\n",
    "\n",
    "    return elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c87946-87aa-4b07-823a-baad715abd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be35118-34d6-470d-8b19-141d229405f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use quantization to make the model faster\n",
    "backend = \"qnnpack\"\n",
    "unet.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized = torch.quantization.prepare(unet, inplace=False)\n",
    "model_static_quantized = torch.quantization.convert(model_static_quantized, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bee10-068e-47ce-bfdd-4c3b5207fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1\n",
    "train_dataload = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "valid_dataload = DataLoader(valid_dataset, batch_size=batchsize, shuffle=True)\n",
    "xb, yb = next(iter(train_dataload))\n",
    "\n",
    "time_taken_gpu = time_cuda_model(unet, xb, use_cuda=True)\n",
    "time_taken_cpu = time_cuda_model(unet, xb, use_cuda=False)\n",
    "    \n",
    "print(f\"Forward pass time taken on batchsize of {batchsize}: {round(time_taken_cpu, 2)} ms on cpu, {round(time_taken_gpu, 2)} ms on gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81eb555-b1e0-4a77-8e9a-d31e502dd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_static_quantized(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf968d1-1442-4096-a385-f6d1c0fdc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make F score, confusion matrix and ROC curve for model result\n",
    "# Check what the model speed is for cpu and gpu with various batch sizes\n",
    "# Add a K means layer and compare performance\n",
    "# Compare the rgb vs ir channels importance\n",
    "# See if we can really use something fast and simple such as jpeg to find the clouds\n",
    "# Make thresholding decision whether to send the satellite image down to earth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8968c2-78de-43a5-b410-7d0b3b5b3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "#from torchmetrics import ConfusionMatrix, F1Score\n",
    "\n",
    "def evaluate_model(model, trn_dataset, eval_dataset):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    y_pred_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluate model on the whole validation set, batch by batch\n",
    "    for x, y in eval_dataset:\n",
    "        with T.no_grad():\n",
    "            y_pred = model(x)\n",
    "        \n",
    "        x_list.extend(x)\n",
    "        y_list.extend(y)\n",
    "        y_pred_list.extend(y_pred)\n",
    "    \n",
    "    # Classification metrics\n",
    "    #f1 = F1Score(num_classes=2)\n",
    "    #f1_score = f1(y_list, y_pred_list)\n",
    "    \n",
    "    #confmat = ConfusionMatrix(num_classes=2)\n",
    "    #confmat_value = confmat(y_list, y_pred_list)\n",
    "    \n",
    "    f1 = f1_score(y_list, y_pred_list)\n",
    "    cf_matrix = confusion_matrix(y_list, y_pred_list)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
