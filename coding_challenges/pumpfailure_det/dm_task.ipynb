{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99cd03-a9aa-4468-b1bd-c20ee8fa807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585dad54-bc44-4759-87cb-20791d27a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip data.zip if it hasn't been done yet. Expects data.zip on the same level as this notebook.\n",
    "if not os.path.isdir('data'):\n",
    "    print(\"Unzipping data\")\n",
    "    os.makedirs('data')\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e545ea-0d59-4be1-88e5-6879d10b06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from files\n",
    "df_data = pd.read_parquet('data/data.parquet', engine='fastparquet')\n",
    "df_labels = pd.read_csv('data/labels.csv')\n",
    "\n",
    "# Quick view of what the data looks like\n",
    "print(df_data.info(), \"\\n\")\n",
    "print(df_data.describe(), \"\\n\")\n",
    "print(df_data.tail(n=10), \"\\n\")\n",
    "\n",
    "# Quick view of what the labels looks like\n",
    "print(df_labels.info(), \"\\n\")\n",
    "print(df_labels.describe(), \"\\n\")\n",
    "print(df_labels.tail(n=10), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fcd11-011d-40cf-9a3b-d25387a3bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Print some information to examine data ===\n",
    "print(\"N data points: \", len(df_data), \"\\n\")\n",
    "\n",
    "# Amount of machines\n",
    "n_unique_machines = df_data.MachineId.nunique()\n",
    "print(\"Num of unique machine Ids: \", n_unique_machines, \"\\n\")\n",
    "\n",
    "# Amount of unique machine-cycle combos\n",
    "n_unique_cycles = df_data.groupby(['MachineId', 'MeasurementId']).ngroups\n",
    "print(\"Num of unique cycles: \", n_unique_cycles, \"\\n\")\n",
    "\n",
    "# Stats of cycles that each machine goes through (we can maybe use to examine fault trends)\n",
    "machine_cyc_df = df_data.groupby(\"MachineId\")[\"MeasurementId\"].unique()\n",
    "cycles_per_machine = machine_cyc_df.apply(lambda x: len(x))\n",
    "print(\"Cycles per machine stats: \", \"\\n\")\n",
    "print(cycles_per_machine.describe(), \"\\n\")\n",
    "\n",
    "N = 50\n",
    "print(f\"Num of machines with more than {N} cycles: \", len(cycles_per_machine[cycles_per_machine > N]), \"\\n\")\n",
    "\n",
    "# Statistics of amount of measurements per cycle\n",
    "count_df = df_data.groupby(['MachineId', 'MeasurementId'])[\"Pressure\"].count()\n",
    "print(\"Stats of amount of measurements per cycle\", \"\\n\")\n",
    "print(count_df.describe(), \"\\n\")\n",
    "\n",
    "# Number of cycles that are too long\n",
    "print(\"Amount of cycles that are too long\", len(count_df[count_df > 10000]), \"\\n\")\n",
    "\n",
    "# Some wierd cycle with negative ID and too many values (edit: nans)\n",
    "print(\"Entry with too many cycles: \", count_df[count_df > 10000], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c0cfe-1f5d-4c21-85ac-8ab846aef3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Print information on loaded labels ===\n",
    "print(\"N labels: \", len(df_labels), \"\\n\")\n",
    "\n",
    "# Amount of machines to check if same in data\n",
    "n_unique_machines = df_labels.MachineId.nunique()\n",
    "print(\"Num of unique machine Ids: \", n_unique_machines, \"\\n\")\n",
    "\n",
    "# Amount of unique cycles to check if same in data\n",
    "n_unique_cycles = df_labels.MeasurementId.nunique()\n",
    "print(\"Num of unique cycles: \", n_unique_cycles, \"\\n\")\n",
    "\n",
    "# Check for nans\n",
    "print(\"Labels nan values: \", \"\\n\")\n",
    "print(df_labels.isna().sum(), \"\\n\")\n",
    "\n",
    "# Get all ids where pump failure label is nan\n",
    "nan_ids_df = df_labels[df_labels[\"PumpFailed\"].isna()][[\"MachineId\", \"MeasurementId\"]]\n",
    "print(nan_ids_df, \"\\n\")\n",
    "\n",
    "# Comment: It looks like measurementId of -1 coincides with a nan at pumpfailure. \n",
    "\n",
    "# Check label balance\n",
    "print(\"Label ratios: \", \"\\n\")\n",
    "print(df_labels[[\"PumpFailed\", \"SlowStart\", \"SlowEnd\"]].apply(pd.Series.value_counts, normalize=True, dropna=True), \"\\n\")\n",
    "# Comment: An unexpectedly high amount of cycles with pump failures. \n",
    "\n",
    "# Check how slowstarts and ends correlate with pump failure\n",
    "df_labels_cp = df_labels.copy()\n",
    "df_labels_cp = df_labels_cp.astype({\"PumpFailed\": np.float32, \"SlowStart\": np.float32, \"SlowEnd\": np.float32}, errors='raise') \n",
    "df_labels_cp[[\"PumpFailed\", \"SlowStart\", \"SlowEnd\"]].corr()\n",
    "\n",
    "# Comment: Nothing too significant in label correlation matrix, SlowEnd correlates negatively with pumpfailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c0663-ad3f-4c40-b923-c38b329ef2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment: We assume the machines are not related to one another.\n",
    "\n",
    "# Comment: It looks like failure doesn't mean a permanent failure and the machine is continued to be used, which is strange.\n",
    "#print(df_data[df_data[\"MachineId\"]==\"1_0_1\"])\n",
    "#print(df_labels[df_labels[\"MachineId\"]==\"1_0_1\"])\n",
    "\n",
    "# Comment: We can examine whether failure is more likely after a machine has gone through a\n",
    "# specific amount of cycle (or maybe follows a bathtub curve). We will only use machine that have gone \n",
    "# through at least N cycles to avoid normalizing, as well as other potential issues \n",
    "# (some machines only have a few cycles).\n",
    "\n",
    "# Get series of machines and list of cycles (measurements)\n",
    "machines_ser = df_data.groupby(\"MachineId\")[\"MeasurementId\"].unique()\n",
    "\n",
    "N = 100\n",
    "\n",
    "# Get machine ID list\n",
    "failures_indeces_list = []\n",
    "for mach_id, meas_ids in zip(machines_ser.index, machines_ser.values):\n",
    "    if len(meas_ids) > N:\n",
    "        # get labels for all cycles\n",
    "        indeces = df_labels.loc[df_labels[\"MachineId\"]==mach_id, \"PumpFailed\"].values\n",
    "        \n",
    "        # Only use first N indeces to avoid false results above this number.\n",
    "        filt_indeces = indeces[:N]\n",
    "        \n",
    "        # find indeces of failures\n",
    "        failure_indeces = np.where(filt_indeces==True)[0]\n",
    "\n",
    "        # Append failure index\n",
    "        for fi in failure_indeces:\n",
    "            failures_indeces_list.append(fi)\n",
    "            \n",
    "# Histogram the failed indeces\n",
    "_ = plt.hist(failures_indeces_list, bins=10)\n",
    "_ = plt.xlabel(\"N_cycles\")\n",
    "_ = plt.ylabel(\"Failure occurances\")\n",
    "\n",
    "# Comment: We can see that failures happen almost twice as frequently in the initial cycles than later on,\n",
    "# but we don't have enough long cycles to see if the failure rate rises later on.\n",
    "# We can use this info as a feature or additional threshold value for the model decision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9e2a1-6926-4e8e-bd34-4a9f33067556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Plot several normal pressure cycles, failed cycles, slowstart and slowend cycles ============\n",
    "def plot_cycles(cycles, title):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Pressure [KPa]\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    for mach_id, meas_id in zip(cycles[\"MachineId\"], cycles[\"MeasurementId\"]):\n",
    "        # Get pressure data for specific cycle\n",
    "        cyc = df_data.loc[(df_data[\"MachineId\"]==mach_id) & (df_data[\"MeasurementId\"]==meas_id), \"Pressure\"].values\n",
    "        plt.plot(cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38bc58-8e16-49a1-84b9-616352fbb51b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====== Cycles with normal pump\n",
    "\n",
    "# Randomly selected cycles with pump failure\n",
    "df_no_pump_failure = df_labels.loc[df_labels[\"PumpFailed\"]==False ,[\"MachineId\", \"MeasurementId\"]].sample(n=3)\n",
    "\n",
    "# Plot selection\n",
    "plot_cycles(df_no_pump_failure, \"Cycle(s) with normal pump\")\n",
    "\n",
    "# Comment: Normal operation feature various operating pressure levels\n",
    "# Comment: Sometimes pressure values are zero through the whole (normal) cycle, sometimes other strange spikes (bad measurement or label?)\n",
    "# Comment: Normal cycle is usually sharp up and sharp down, with high frequency noise, but without ups and downs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad1099-b80f-428a-b9fb-0b79853b9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Cycles with pump failure\n",
    "\n",
    "# Randomly selected cycles with pump failure\n",
    "df_with_pump_failure = df_labels.loc[df_labels[\"PumpFailed\"]==True ,[\"MachineId\", \"MeasurementId\"]].sample(n=3)\n",
    "\n",
    "# Plot selection\n",
    "plot_cycles(df_with_pump_failure, \"Cycle(s) with pump failure\")\n",
    "\n",
    "# Comment: Relatively consistent failure feature is a dip in pressure after initial pressure rise, otherwise normal pressure levels are usually reached.\n",
    "# The dip in pressure spans roughly 50 time units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fd50f-0591-4a11-8df8-60f7d3268d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====== Cycles with slow start\n",
    "\n",
    "# Randomly selected cycles with pump failure\n",
    "df_slow_start = df_labels.loc[df_labels[\"SlowStart\"]==True ,[\"MachineId\", \"MeasurementId\"]].sample(n=3)\n",
    "\n",
    "# Plot selection\n",
    "plot_cycles(df_slow_start, \"Cycle(s) with slow start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a3949-c1c1-4e27-bbe4-c68eac0d7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Cycles with slow end\n",
    "\n",
    "# Randomly selected cycles with pump failure\n",
    "df_slow_end = df_labels.loc[df_labels[\"SlowEnd\"]==True ,[\"MachineId\", \"MeasurementId\"]].sample(n=3)\n",
    "\n",
    "# Plot selection\n",
    "plot_cycles(df_slow_end, \"Cycle(s) with slow end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335b091-f476-4bb6-9c35-82472f9ac7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Merge the data and labels dataframes === \n",
    "\n",
    "# Group the pressure measurements in each cycle into a list\n",
    "df_data_gr = df_data.groupby([\"MachineId\", \"MeasurementId\"])[\"Pressure\"].apply(list).reset_index()\n",
    "\n",
    "# Merge on matching columns (MachineId and MeasurementId)\n",
    "df_comb = pd.merge(df_data_gr, df_labels)\n",
    "\n",
    "# Remove rows with nan pressure or pumpfailed data\n",
    "df_comb = df_comb.dropna(subset=[\"Pressure\", \"PumpFailed\"], axis=0)\n",
    "\n",
    "print(df_comb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b3c4b-afcb-4bca-b91e-cc768491568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Get data into X, Y ndarray form, clean, trim, pad, and normalize (maybe)\n",
    "\n",
    "# List of lists of pressure measurements  \n",
    "X = df_comb[\"Pressure\"].values\n",
    "\n",
    "# TODO: Get machine cycle number feature and cycle length feature to add to pressure list \n",
    "\n",
    "# Get labels\n",
    "Y = df_comb[\"PumpFailed\"].values\n",
    "\n",
    "# Make small subsequence for fast testing (comment this line later)\n",
    "#X_list = X_list[0:50]\n",
    "\n",
    "# Trim each sequence to get just the cycle information\n",
    "thresh = 0.05\n",
    "X_trimmed = []\n",
    "Y_trimmed = []\n",
    "X_short = []\n",
    "Y_short = []\n",
    "shortest_seq = 0\n",
    "longest_seq = 0\n",
    "for x, y in zip(X, Y):\n",
    "    # First occurance of val above thresh\n",
    "    init_idx = np.argmax(np.array(x) > thresh)\n",
    "    \n",
    "    # Last occurance of val above thresh\n",
    "    last_idx = len(x) - np.argmax(np.array(list(reversed(x))) > thresh)\n",
    "    \n",
    "    # Make sure no anomalous sequence gets in\n",
    "    seq_len = last_idx - init_idx \n",
    "    \n",
    "    # Exclude very short sequences\n",
    "    if seq_len > 20:\n",
    "        X_trimmed.append(x[init_idx:last_idx])\n",
    "        Y_trimmed.append(y)\n",
    "    else:\n",
    "        # Append whole cycle for plot\n",
    "        X_short.append(x[init_idx:last_idx])\n",
    "        Y_short.append(y)\n",
    "    \n",
    "    shortest_seq = seq_len if seq_len < shortest_seq else shortest_seq\n",
    "    longest_seq = seq_len if seq_len > longest_seq else longest_seq\n",
    "    \n",
    "# Short sequence lengths\n",
    "print([len(x) for x in X_short], \"\\n\")\n",
    "# Comment: Some sequences are way too short in comparison with the nominal length for any meaningful classification.\n",
    "\n",
    "# Short sequence labels\n",
    "print(Y_short, \"\\n\")\n",
    "# Comment: All strangely short sequences have negative pump failure label.\n",
    "# It's probably better to classify all short sequences as non-failures..\n",
    "    \n",
    "print(\"Shortest seq: \", shortest_seq, \"Longest seq: \", longest_seq, \"N short seqs: \", len(X_short), \"N norm seqs: \", len(X_trimmed), \"\\n\")\n",
    "\n",
    "# Plot some of the very short cycles to see what is going on there\n",
    "# for i in range(1):\n",
    "#    cyc = X_short[np.random.randint(0, len(X_short))]\n",
    "#    plt.plot(np.arange(len(cyc)), cyc)\n",
    "\n",
    "# for i in range(3):\n",
    "#    cyc = X_trimmed[np.random.randint(0, len(X_trimmed))]\n",
    "#    plt.plot(np.arange(len(cyc)), cyc)\n",
    "\n",
    "# Histogram of cycle lengths\n",
    "_ = plt.hist([len(x) for x in X_trimmed])\n",
    "\n",
    "# Based on above histogram, we will cut all sequences and pad to max_time_units \n",
    "max_time_units = 600\n",
    "X_padded = []\n",
    "for x in X_trimmed:\n",
    "    if len(x) > max_time_units:\n",
    "        X_padded.append(x[:max_time_units])\n",
    "    else:\n",
    "        X_padded.append(x + [0] * (max_time_units - len(x)))\n",
    "        \n",
    "    assert len(X_padded[-1]) == max_time_units\n",
    "\n",
    "# Prepared array data for training\n",
    "X = np.array(X_padded, dtype=np.float32)\n",
    "Y = np.array(Y_trimmed, dtype=np.int_)\n",
    "\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2697a-1ab9-4fc0-9b19-1b3e9a40dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Assume that we want to predict pump failure after the cycle completes. \n",
    "# Fit baseline model on raw padded pressure data for baseline. Treat sequence as static example. ==\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "N_data = len(X) # Use subset of data if necessary\n",
    "seqlen = 600 # limit sequence length if necessary (MAX 600)\n",
    "skip = 1 # Every data point is probably not necessary, we can skip every nth\n",
    "\n",
    "# Split into training and test data\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        sklearn.model_selection.train_test_split(X[:N_data, 0:seqlen:skip], Y[:N_data], random_state=1337, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fb3e1-e491-4495-b1dd-dde69a93ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating the classifier (F1 score, confusion matrix, prec-recall curve).\n",
    "def evaluate_classif(clf, X_train, y_train, X_test, y_test, model_name):\n",
    "    y_hat = clf.predict(X_train)\n",
    "    print(\"F1 score on trn\", sklearn.metrics.f1_score(y_train, y_hat))\n",
    "\n",
    "    y_hat_tst = clf.predict(X_test)\n",
    "    print(\"F1 score on tst\", sklearn.metrics.f1_score(y_test, y_hat_tst))\n",
    "\n",
    "    display_cm = sklearn.metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "            clf,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            display_labels=[\"normal\", \"failed\"],\n",
    "            cmap=plt.cm.Blues,\n",
    "        )\n",
    "\n",
    "    _ = display_cm.ax_.set_title(\"2-class Confusion matrix\")\n",
    "\n",
    "    display_pr = sklearn.metrics.PrecisionRecallDisplay.from_estimator(\n",
    "        clf, X_test, y_test, name=model_name\n",
    "    )\n",
    "    _ = display_pr.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569431d6-7103-4706-a1e0-02e24395cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the sequence as a single example (Warning: don't use GP with the entire dataset, it will likely try to allocate too much memory)\n",
    "model_name = \"MLP\"\n",
    "clf_dict = {\"MLP\" : MLPClassifier(),\n",
    "            \"GP\" : GaussianProcessClassifier(copy_X_train=False)}\n",
    "\n",
    "clf = make_pipeline(clf_dict[model_name]) # StandardScaler(), \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "evaluate_classif(clf, X_train, y_train, X_test, y_test, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9130ea-883e-444a-9d2e-60e33c6119ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Nuclear option: Use RNN or convolutions to classify sequence. ==\n",
    "import torch as T\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, obs_dim=1, act_dim=2, hid_dim=16):\n",
    "        super(RNN, self).__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        num_layers = 1 \n",
    "\n",
    "        self.rnn_1 = T.nn.LSTM(input_size=self.obs_dim, hidden_size=self.hid_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc2 = T.nn.Linear(self.hid_dim, self.act_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_rs = x.unsqueeze(2)\n",
    "        rnn_1, _ = self.rnn_1(x_rs, None)\n",
    "        rnn_last = rnn_1[:, -1, :]\n",
    "        fc2 = self.fc2(rnn_last)\n",
    "        out = F.softmax(fc2, dim=-1)\n",
    "        return out\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv1d(\n",
    "                in_channels=1,            \n",
    "                out_channels=16,         \n",
    "                kernel_size=5,              \n",
    "                stride=2,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool1d(kernel_size=2),  \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv1d(\n",
    "                in_channels=16,             \n",
    "                out_channels=8,             \n",
    "                kernel_size=5,              \n",
    "                stride=2,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool1d(kernel_size=2),    \n",
    "            \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv1d(\n",
    "                in_channels=8,             \n",
    "                out_channels=8,             \n",
    "                kernel_size=3,              \n",
    "                stride=1,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool1d(kernel_size=2),    \n",
    "            \n",
    "        )\n",
    "        self.conv4 = nn.Sequential(         \n",
    "            nn.Conv1d(\n",
    "                in_channels=8,             \n",
    "                out_channels=8,             \n",
    "                kernel_size=3,              \n",
    "                stride=1,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool1d(kernel_size=2),    \n",
    "        )\n",
    "        self.out = nn.Linear(8 * 7, 2) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.reshape((-1, 8 * 7))\n",
    "        output = F.softmax(self.out(x), dim=-1)\n",
    "        return output\n",
    "    \n",
    "# CNN works (F=0.73, AP=0.8), RNN has some issue, doesn't train.\n",
    "clf = NeuralNetClassifier(\n",
    "    CNN,\n",
    "    max_epochs=30,\n",
    "    lr=0.01,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    optimizer=T.optim.Adam\n",
    ")\n",
    "\n",
    "# Train and evaluate model\n",
    "model_name = \"NN\"\n",
    "clf.fit(X_train, y_train) \n",
    "evaluate_classif(clf, X_train, y_train, X_test, y_test, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1d0ad-5ab1-41e5-8e1e-d2ceb632f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Experimental: Use low frequency real+imag FFT features with a classifier to try classify the typical failure kink that happens at the beginning ==\n",
    "N_data = len(X) # Use subset of data if necessary\n",
    "seqlen = 600 # limit sequence length if necessary (MAX 600)\n",
    "skip = 1 # Every data point is probably not necessary, we can skip every nth\n",
    "\n",
    "# Get fft of data\n",
    "X_fft_comp = np.fft.rfft(X[:N_data, 0:seqlen:skip], norm=\"forward\")\n",
    "\n",
    "# Make just get the first n_feats frequencies and concatenate the real(amplitudes) + imag(phases) parts.\n",
    "n_feats = 20\n",
    "X_fft = np.concatenate((X_fft_comp.real[:, :n_feats], X_fft_comp.imag[:, :n_feats]), axis=1)\n",
    "\n",
    "# Split into training and test data\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "       sklearn.model_selection.train_test_split(X_fft[:N_data, 0:seqlen:skip], Y[:N_data], random_state=1337, train_size=0.9)\n",
    "\n",
    "# Train and evaluate\n",
    "model_name = \"MLP\"\n",
    "clf_dict = {\"MLP\" : MLPClassifier(alpha=1e-5, hidden_layer_sizes=(20, 20), solver=\"adam\", learning_rate_init=0.003),\n",
    "            \"AB\" : AdaBoostClassifier()}\n",
    "clf = make_pipeline(StandardScaler(), clf_dict[model_name]) \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "evaluate_classif(clf, X_train, y_train, X_test, y_test, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9440d-8687-4533-950b-21452a788233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Experimental: Test simple handcrafted algorithm for the typical failure kink detection. (doesn't work) ==\n",
    "\n",
    "# Classifier parameters\n",
    "window_width = 15\n",
    "\n",
    "# Params: t1 = 0.138, t2 = 0.39, t3 = 0.97\n",
    "def manual_classifier(seq, params):\n",
    "    \"\"\"\n",
    "        Define several relative hystereses thresholds and go over the whole sequence one by one to see if we can detect the up-down-up characteristic of the kink\n",
    "        Return true if the sequence features a pump failure\n",
    "    \"\"\"\n",
    "    \n",
    "    t1, t2, t3 = params\n",
    "    \n",
    "    # Filter high frequency noise from sequence\n",
    "    cumsum_vec = np.cumsum(np.insert(seq, 0, 0)) \n",
    "    seq_filt = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "    \n",
    "    pivot = 0\n",
    "    cur_max_val = 0\n",
    "    cur_min_val = 10\n",
    "    state = 0\n",
    "    for i in range(np.minimum(len(seq_filt), 100)):\n",
    "        val = seq_filt[i]\n",
    "        \n",
    "        if val > cur_max_val:\n",
    "            cur_max_val = val\n",
    "        if val < cur_min_val:\n",
    "            cur_min_val = val\n",
    "                \n",
    "        if state == 0:\n",
    "            # In this state the sequence is rising from the start\n",
    "            if val < cur_max_val - t1:\n",
    "                cur_max_val = 0\n",
    "                cur_min_val = 10\n",
    "                state = 1\n",
    "        if state == 1:\n",
    "            # In this state we have already had our failure and pressure is dropping\n",
    "            if val > cur_min_val + t2:\n",
    "                cur_max_val = 0\n",
    "                cur_min_val = 10\n",
    "                state = 2\n",
    "        if state == 2:\n",
    "            # In this state the pressure is rising after the drop and we will just check that it rises above a certain threshold\n",
    "            if val > cur_min_val + t3:\n",
    "                return True\n",
    "        \n",
    "    return False\n",
    "        \n",
    "import optuna\n",
    "import random\n",
    "\n",
    "def objective(X, Y, classif, trial):\n",
    "    t1 = trial.suggest_float(\"t1\", 0.1, 1)\n",
    "    t2 = trial.suggest_float(\"t2\", 0.1, 1)\n",
    "    t3 = trial.suggest_float(\"t3\", 0.1, 1)\n",
    "    params = t1, t2, t3\n",
    "        \n",
    "    batchsize=300\n",
    "    indeces_subset = random.sample(range(0, len(X)), batchsize)\n",
    "    X_subset = X[indeces_subset]\n",
    "    Y_subset = Y[indeces_subset]\n",
    "    \n",
    "    Y_ = np.array([classif(x, params) for x in X_subset])\n",
    "    \n",
    "    score = (Y_subset == Y_).sum()\n",
    "    \n",
    "    return score\n",
    "    \n",
    "timeout = 20.0\n",
    "print(f\"Running optimization for {timeout} seconds...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(lambda t : objective(X, Y, manual_classifier, t), timeout=timeout)\n",
    "\n",
    "print(f\"Best value is : {study.best_value}, with param vec: {study.best_params}\")\n",
    "\n",
    "params = [study.best_params['t1'],\n",
    "          study.best_params['t2'],\n",
    "          study.best_params['t3']]\n",
    "\n",
    "# == Evaluate\n",
    "\n",
    "# N data points\n",
    "N = 1000\n",
    "\n",
    "# Evaluate the classifier\n",
    "Y_ = np.array([manual_classifier(x, params) for x in X[:N]])\n",
    "\n",
    "# True positives\n",
    "tp = (Y_ & Y[:N]).sum()\n",
    "\n",
    "# True negatives\n",
    "tn = (~Y_ & ~Y[:N]).sum()\n",
    "\n",
    "# False positives\n",
    "fp = (Y_ & ~Y[:N]).sum()\n",
    "\n",
    "# False negatives\n",
    "fn = (~Y_ & Y[:N]).sum()\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "rec = tp / (tp + fn)\n",
    "F = (2 * prec * rec) / (prec + rec)\n",
    "\n",
    "print(f\"True positives: {tp}, True negatives: {tn}, False positives: {fp}, False negatives: {fn}, Precision: {prec}, Recall: {rec}, F-score: {F}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
